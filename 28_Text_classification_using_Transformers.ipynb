{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e2cR8o2NGLVb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 08:49:09.861185: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-22 08:49:09.865055: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 08:49:09.921958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 08:49:09.921996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 08:49:09.923385: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 08:49:09.932284: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 08:49:09.933054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 08:49:10.886825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EaNOm7g4HMBb"
   },
   "outputs": [],
   "source": [
    "class TransformersBlock(Layer):\n",
    "    def __init__(self, embed_dim,num_heads, ff_dim, rate=0.1):\n",
    "         #embed_dim: This paramater specifies the dimensionality of the input and output\n",
    "         #num_heads: This parameter controls the number of attention heads\n",
    "         # ff_dim: This parameter specifies the dimensionality of the feedforward network\n",
    "         # rate: This parameter controls the dropout rate, which is used to\n",
    "\n",
    "         super().__init__()\n",
    "         self.att = MultiHeadAttention(num_heads, key_dim=embed_dim)\n",
    "         # This creates a MultiHeadAttention layer, responsible for learning\n",
    "         self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"),Dense(embed_dim),]\n",
    "         )\n",
    "         # self.ffn: This creates a feedforward network, often used for\n",
    "         self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "         self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "         # self.layernorm1 and self.layernorm2: These create LayerNormalization\n",
    "         self.dropout1 = Dropout(rate)\n",
    "         self.dropout2 = Dropout(rate)\n",
    "         # self.dropout1 and self.dropout2: Thse create Dropout layers, rate\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output =self.att(inputs,inputs)\n",
    "        # Applies multi-head attention to the input sequence, allowing\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # Applies dropout to the attention output\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        # Adds the attention output to th eoriginal input and applies layer\n",
    "        ffn_output = self.ffn(out1)\n",
    "        # Passes the normalized output through the feedforward network\n",
    "        ffn_output = self.dropout2(attn_output, training=training)\n",
    "        # Applies dropout to the feedforward output\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "        # Adds the feedforward output to the previous layer's output and a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GtGrbuifNj2K"
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        # maxlen: The maximum length of the input sequences the model will\n",
    "        # vocab_size: The total number of unique tokens (words) in the vocabulary\n",
    "        # embed_dim: the dimensionality of the embeddings (how each token)\n",
    "        super().__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        # An Embedding layer that maps each token on the input sequence\n",
    "        # to a dense vector of size embed_dim\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        #An Embedding layer that maps each position in the sequence\n",
    "        # (from 0 to maxlen-1) to a dense vector of size embed_dim.\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        # Extracts the actual length of the current input sequence.\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        # Create a tensor of positions from 0 to maxlen-1.\n",
    "        positions = self.pos_emb(positions)\n",
    "        #Looks up the position embeddings for each position in that sequence\n",
    "        x=self.token_emb(x)\n",
    "        # Looks up the token embeddings for each token in the input sequence\n",
    "        return x + positions\n",
    "        # Adds the token embeddings and position embeddings element-wise,resulting in A COMBINED REPRESENTATION THAT CAPTURES both word meanng and positional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rt3EVLQL95d",
    "outputId": "40fa0ef8-9833-4f9c-bbc5-165b6889c505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size=20000  # Only consider the top 20k words\n",
    "maxlen = 200 # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train),\"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oTO0XgBQZIU",
    "outputId": "215157cf-ceee-48f2-f287-979d12179272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200), (25000, 200))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TFkqRWKxQ33_"
   },
   "outputs": [],
   "source": [
    "embed_dim = 32    #Embedding size for each token\n",
    "num_heads = 2    # Number of attention heads\n",
    "ff_dim = 32       # Hidden layer size in feed forword network inside transformer\n",
    "\n",
    "inputs = Input(shape = (maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformersBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20,activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "782/782 [==============================] - 45s 55ms/step - loss: 0.3678 - accuracy: 0.8355 - val_loss: 0.2884 - val_accuracy: 0.8775\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.2004 - accuracy: 0.9234 - val_loss: 0.3162 - val_accuracy: 0.8688\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.1337 - accuracy: 0.9517 - val_loss: 0.3959 - val_accuracy: 0.8592\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.0929 - accuracy: 0.9675 - val_loss: 0.4717 - val_accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.0658 - accuracy: 0.9780 - val_loss: 0.5814 - val_accuracy: 0.8290\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.6844 - val_accuracy: 0.8446\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.6441 - val_accuracy: 0.8426\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.8539 - val_accuracy: 0.8394\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.8410 - val_accuracy: 0.8263\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.7499 - val_accuracy: 0.8297\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model \n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=32,epochs=10,\n",
    "                    validation_data=[x_val,y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
